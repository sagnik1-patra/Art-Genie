{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62e400b-7055-4cf6-a6f2-dc53eda82c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "  python ipykernel_launcher.py --input <CSV> [--out <CSV>] [--no_ids]\n",
      "Defaults:\n",
      "  Artifacts dir: C:\\Users\\sagni\\Downloads\\Art Genie\n",
      "  Output: C:\\Users\\sagni\\Downloads\\Art Genie\\predictions.csv\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# =========================\n",
    "# User knobs for Notebook\n",
    "# =========================\n",
    "INPUT_PATH  = r\"\"  # e.g., r\"C:\\Users\\sagni\\Downloads\\Art Genie\\archive\\wikiart_scraped.csv\"\n",
    "OUTPUT_PATH = r\"\"  # e.g., r\"C:\\Users\\sagni\\Downloads\\Art Genie\\predictions.csv\"\n",
    "RUN_NOW     = False  # set True in notebooks to execute immediately\n",
    "\n",
    "# =========================\n",
    "# Artifacts & Outputs\n",
    "# =========================\n",
    "ARTIFACT_DIR   = r\"C:\\Users\\sagni\\Downloads\\Art Genie\"\n",
    "PKL_PATH       = os.path.join(ARTIFACT_DIR, \"artgenie_textclf.pkl\")\n",
    "H5_PATH        = os.path.join(ARTIFACT_DIR, \"artgenie_textclf.h5\")\n",
    "HISTORY_CSV    = os.path.join(ARTIFACT_DIR, \"history.csv\")\n",
    "\n",
    "DEFAULT_OUT    = os.path.join(ARTIFACT_DIR, \"predictions.csv\")\n",
    "ACC_PNG        = os.path.join(ARTIFACT_DIR, \"accuracy_curve.png\")\n",
    "CONF_FULL_CSV  = os.path.join(ARTIFACT_DIR, \"confusion_matrix_full.csv\")\n",
    "HEATMAP_PNG    = os.path.join(ARTIFACT_DIR, \"confusion_heatmap_top25.png\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "\n",
    "# =========================\n",
    "# Helpers (match training)\n",
    "# =========================\n",
    "POSSIBLE_TEXT_COLS = [\n",
    "    \"title\",\"description\",\"caption\",\"tags\",\"genre\",\"style\",\"artist\",\n",
    "    \"movement\",\"content\",\"about\",\"wiki\",\"text\",\"meta\",\"materials\",\"subject\"\n",
    "]\n",
    "POSSIBLE_LABEL_COLS = [\"style\",\"genre\",\"artist\",\"label\"]\n",
    "\n",
    "def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out.columns = [str(c).strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "    return out\n",
    "\n",
    "def canonicalize(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s).lower()).strip()\n",
    "\n",
    "def collect_text_columns(df: pd.DataFrame) -> List[str]:\n",
    "    cols = [c for c in POSSIBLE_TEXT_COLS if c in df.columns]\n",
    "    if not cols:\n",
    "        cols = [c for c in df.columns if df[c].dtype == object]\n",
    "    return cols[:8]\n",
    "\n",
    "def build_text_series(df: pd.DataFrame, text_cols: List[str]) -> pd.Series:\n",
    "    if not text_cols:\n",
    "        raise ValueError(\"No text columns found to build input.\")\n",
    "    parts = [df[c].astype(str) for c in text_cols]\n",
    "    txt = parts[0]\n",
    "    for p in parts[1:]:\n",
    "        txt = txt.str.cat(p, sep=\" . \", na_rep=\"\")\n",
    "    return txt.fillna(\"\").map(lambda s: re.sub(r\"\\s+\", \" \", str(s)).strip())\n",
    "\n",
    "def pick_label_column(df: pd.DataFrame) -> Optional[str]:\n",
    "    for c in POSSIBLE_LABEL_COLS:\n",
    "        if c in df.columns and df[c].notna().any():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# =========================\n",
    "# Plotting\n",
    "# =========================\n",
    "def plot_accuracy_curve(history_csv: str, out_png: str, also_show: bool = True):\n",
    "    if not os.path.exists(history_csv):\n",
    "        logging.warning(f\"[PLOT] history.csv not found at {history_csv} — skipping accuracy plot.\")\n",
    "        return\n",
    "    hist = pd.read_csv(history_csv)\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    if \"accuracy\" in hist.columns:\n",
    "        plt.plot(hist[\"epoch\"], hist[\"accuracy\"], label=\"Train Accuracy\")\n",
    "    if \"val_accuracy\" in hist.columns:\n",
    "        plt.plot(hist[\"epoch\"], hist[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "    if \"top3_acc\" in hist.columns:\n",
    "        plt.plot(hist[\"epoch\"], hist[\"top3_acc\"], label=\"Train Top-3\")\n",
    "    if \"val_top3_acc\" in hist.columns:\n",
    "        plt.plot(hist[\"epoch\"], hist[\"val_top3_acc\"], label=\"Val Top-3\")\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(); plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=160)\n",
    "    if also_show:\n",
    "        try: plt.show()\n",
    "        except Exception: pass\n",
    "    plt.close()\n",
    "    logging.info(f\"[PLOT] Saved accuracy curve → {out_png}\")\n",
    "\n",
    "def plot_confusion_heatmap(y_true_idx, y_pred_idx, class_names, out_png: str, full_csv: str, top_k: int = 25, also_show: bool = True):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_full = confusion_matrix(y_true_idx, y_pred_idx, labels=np.arange(len(class_names)))\n",
    "    # Save full confusion matrix\n",
    "    df_full = pd.DataFrame(cm_full, index=class_names, columns=class_names)\n",
    "    df_full.to_csv(full_csv, encoding=\"utf-8\")\n",
    "    logging.info(f\"[PLOT] Saved full confusion matrix CSV → {full_csv}\")\n",
    "\n",
    "    # Top-K by true frequency\n",
    "    true_counts = cm_full.sum(axis=1)\n",
    "    top_idx = np.argsort(true_counts)[::-1][:min(top_k, len(class_names))]\n",
    "    sub = cm_full[np.ix_(top_idx, top_idx)]\n",
    "    sub_labels = [class_names[i] for i in top_idx]\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    im = plt.imshow(sub, interpolation=\"nearest\", aspect=\"auto\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.title(f\"Confusion Matrix Heatmap (Top {len(sub_labels)} Classes)\")\n",
    "    plt.xticks(range(len(sub_labels)), sub_labels, rotation=90)\n",
    "    plt.yticks(range(len(sub_labels)), sub_labels)\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=160)\n",
    "    if also_show:\n",
    "        try: plt.show()\n",
    "        except Exception: pass\n",
    "    plt.close()\n",
    "    logging.info(f\"[PLOT] Saved confusion heatmap → {out_png}\")\n",
    "\n",
    "# =========================\n",
    "# Core: predict + plots\n",
    "# =========================\n",
    "def predict_and_plot(input_csv: str, output_csv: str = DEFAULT_OUT, include_ids=True):\n",
    "    # Load artifacts\n",
    "    if not os.path.exists(PKL_PATH):\n",
    "        raise FileNotFoundError(f\"Missing sklearn pipeline PKL: {PKL_PATH}\")\n",
    "    if not os.path.exists(H5_PATH):\n",
    "        raise FileNotFoundError(f\"Missing Keras model H5: {H5_PATH}\")\n",
    "\n",
    "    bundle = joblib.load(PKL_PATH)  # {\"pipeline\": ..., \"label_encoder\": ...}\n",
    "    sk_pipe = bundle[\"pipeline\"]\n",
    "    label_encoder = bundle[\"label_encoder\"]\n",
    "    class_names = list(label_encoder.classes_)\n",
    "    num_classes = len(class_names)\n",
    "    logging.info(f\"[LOAD] Classes: {num_classes}\")\n",
    "\n",
    "    keras_model = load_model(H5_PATH)  # contains TextVectorization layer\n",
    "\n",
    "    # Read input\n",
    "    if not os.path.exists(input_csv):\n",
    "        raise FileNotFoundError(f\"Input CSV not found: {input_csv}\")\n",
    "    logging.info(f\"[READ] {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, engine=\"python\")\n",
    "    df = normalize_cols(df)\n",
    "\n",
    "    # Build text like training\n",
    "    text_cols = collect_text_columns(df)\n",
    "    logging.info(f\"[TEXT] Using columns: {text_cols}\")\n",
    "    df[\"__text__\"] = build_text_series(df, text_cols)\n",
    "\n",
    "    # Optional ground-truth for heatmap\n",
    "    lbl_col = pick_label_column(df)\n",
    "    if lbl_col:\n",
    "        df[lbl_col] = df[lbl_col].astype(str).map(canonicalize)\n",
    "\n",
    "    id_cols = [c for c in [\"style\",\"genre\",\"artist\",\"title\"] if c in df.columns] if include_ids else []\n",
    "    texts = df[\"__text__\"].fillna(\"\").astype(str).values\n",
    "\n",
    "    # 1) sklearn predictions\n",
    "    logging.info(\"[PRED] sklearn pipeline…\")\n",
    "    prob_sk = None\n",
    "    try:\n",
    "        prob_sk = sk_pipe.predict_proba(texts)\n",
    "        idx_sk = np.argmax(prob_sk, axis=1)\n",
    "        conf_sk = prob_sk[np.arange(len(idx_sk)), idx_sk]\n",
    "    except Exception:\n",
    "        idx_sk = sk_pipe.predict(texts)\n",
    "        conf_sk = np.full_like(idx_sk, np.nan, dtype=float)\n",
    "    pred_sk = label_encoder.inverse_transform(idx_sk)\n",
    "\n",
    "    # 2) Keras predictions\n",
    "    logging.info(\"[PRED] Keras .h5 model…\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices(texts).batch(256)\n",
    "    prob_k = keras_model.predict(ds, verbose=0)\n",
    "    idx_k = np.argmax(prob_k, axis=1)\n",
    "    conf_k = prob_k[np.arange(len(idx_k)), idx_k]\n",
    "    pred_k = label_encoder.inverse_transform(idx_k)\n",
    "\n",
    "    # 3) Simple average ensemble (if both prob available & aligned)\n",
    "    if prob_sk is not None and prob_sk.shape == prob_k.shape == (len(texts), num_classes):\n",
    "        avg_prob = (prob_sk + prob_k) / 2.0\n",
    "        idx_avg = np.argmax(avg_prob, axis=1)\n",
    "        conf_avg = avg_prob[np.arange(len(idx_avg)), idx_avg]\n",
    "        pred_avg = label_encoder.inverse_transform(idx_avg)\n",
    "    else:\n",
    "        idx_avg, conf_avg, pred_avg = idx_k, conf_k, pred_k\n",
    "\n",
    "    # Save predictions\n",
    "    out = pd.DataFrame({\n",
    "        \"pred_sklearn\": pred_sk,\n",
    "        \"pred_sklearn_conf\": conf_sk,\n",
    "        \"pred_keras\": pred_k,\n",
    "        \"pred_keras_conf\": conf_k,\n",
    "        \"pred_avg\": pred_avg,\n",
    "        \"pred_avg_conf\": conf_avg\n",
    "    })\n",
    "    if id_cols:\n",
    "        out = pd.concat([df[id_cols].reset_index(drop=True), out.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_csv) or \".\", exist_ok=True)\n",
    "    out.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "    logging.info(f\"[SAVE] Predictions → {output_csv}\")\n",
    "\n",
    "    # Plots\n",
    "    plot_accuracy_curve(HISTORY_CSV, ACC_PNG, also_show=True)\n",
    "\n",
    "    if lbl_col:\n",
    "        logging.info(f\"[EVAL] Found ground-truth column '{lbl_col}' — building confusion heatmap.\")\n",
    "        y_true_names = df[lbl_col].values\n",
    "        is_known = np.isin(y_true_names, class_names)\n",
    "        if np.any(is_known):\n",
    "            y_true_idx = label_encoder.transform(y_true_names[is_known])\n",
    "            y_pred_idx = idx_k[is_known]\n",
    "            plot_confusion_heatmap(\n",
    "                y_true_idx, y_pred_idx, class_names,\n",
    "                out_png=HEATMAP_PNG, full_csv=CONF_FULL_CSV, top_k=25, also_show=True\n",
    "            )\n",
    "        else:\n",
    "            logging.warning(\"[EVAL] None of the true labels match training classes — skipping heatmap.\")\n",
    "    else:\n",
    "        logging.info(\"[EVAL] No true label column — skipping confusion heatmap.\")\n",
    "\n",
    "    return output_csv\n",
    "\n",
    "# =========================\n",
    "# CLI (Notebook-safe)\n",
    "# =========================\n",
    "def _maybe_parse_cli_args(argv):\n",
    "    args = {\"input\": None, \"out\": DEFAULT_OUT, \"include_ids\": True}\n",
    "    toks = list(argv[1:])\n",
    "    i = 0\n",
    "    while i < len(toks):\n",
    "        t = toks[i]\n",
    "        if t == \"--input\" and i + 1 < len(toks):\n",
    "            args[\"input\"] = toks[i+1]; i += 2\n",
    "        elif t == \"--out\" and i + 1 < len(toks):\n",
    "            args[\"out\"] = toks[i+1]; i += 2\n",
    "        elif t == \"--no_ids\":\n",
    "            args[\"include_ids\"] = False; i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    return args\n",
    "\n",
    "def _running_in_ipython() -> bool:\n",
    "    try:\n",
    "        from IPython import get_ipython  # noqa\n",
    "        return get_ipython() is not None\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Notebook one-click run\n",
    "    if _running_in_ipython() and RUN_NOW:\n",
    "        if not INPUT_PATH:\n",
    "            raise ValueError(\"Set INPUT_PATH at the top before RUN_NOW=True.\")\n",
    "        out_path = OUTPUT_PATH or DEFAULT_OUT\n",
    "        predict_and_plot(INPUT_PATH, out_path, include_ids=True)\n",
    "        return\n",
    "\n",
    "    # Terminal / default path\n",
    "    args = _maybe_parse_cli_args(sys.argv)\n",
    "    if not args[\"input\"]:\n",
    "        script_name = os.path.basename(sys.argv[0]) if \"__file__\" not in globals() else os.path.basename(__file__)\n",
    "        print(f\"Usage:\\n  python {script_name} --input <CSV> [--out <CSV>] [--no_ids]\")\n",
    "        print(f\"Defaults:\\n  Artifacts dir: {ARTIFACT_DIR}\\n  Output: {DEFAULT_OUT}\")\n",
    "        sys.exit(2)\n",
    "    predict_and_plot(args[\"input\"], args[\"out\"], include_ids=args[\"include_ids\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea10e2-b4bb-4c73-bd57-246daf630c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
